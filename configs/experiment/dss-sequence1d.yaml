# @package _global_
defaults:
  - /pipeline: adding
  - /model: dss
  - override /dataset: sequence1d
  
dataset:
  samples_per_epoch: 16000
  val_split: 0.1
  L: 4096
  task: reverse
  D: 4                # mips: query/key/val dim
  causal: True        # mips: only prev keys matched
  M: 32               # masked_select: num tokens to copy
  variable: True      # masked_select: vary positions to copy across batches
  consecutive: False  # masked_select: use consecutive positions to copy
  num_shifts: 8       # shift task

model:
  dropout: 0.0
  n_layers: 1           # to not rely on depth
  prenorm: false
  d_model: 128
  norm: layer
  layer:
    activation: gelu
    postact: null
    lr:
      Lambda: 0.0001
      W: 0.0001

optimizer:
  lr: 0.0001      

loader:
  batch_size: 16
  num_workers: 4

trainer:
  max_epochs: 12

train:
  seed: 1112
